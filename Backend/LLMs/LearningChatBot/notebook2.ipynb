{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if not groq_api_key:\n",
    "    raise ValueError(\"Groq API key not found in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zubay\\.conda\\envs\\fyp\\Lib\\importlib\\__init__.py:90: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "C:\\Users\\zubay\\AppData\\Local\\Temp\\ipykernel_23056\\3585118731.py:13: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\zubay\\.conda\\envs\\fyp\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\zubay\\.conda\\envs\\fyp\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "# Initialize the HuggingFace Embedding Model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents from a text file and add metadata\n",
    "def load_documents(file_path):\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Add metadata to each document (e.g., file name)\n",
    "    for doc in documents:\n",
    "        doc.metadata[\"source\"] = file_path\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your subtopic and chapter separators\n",
    "subtopic_pattern = re.compile(r'(\\d+(\\.\\d+)+)')\n",
    "chapter_separator = 'chapter end -------------------------------------'\n",
    "\n",
    "\n",
    "# Custom RecursiveCharacterTextSplitter with regex patterns for subtopics and chapters\n",
    "class CustomTextSplitter(RecursiveCharacterTextSplitter):\n",
    "    def __init__(self, **kwargs):\n",
    "        # Initialize with any other parameters, and add your separators\n",
    "        super().__init__(separators=[chapter_separator], **kwargs)\n",
    "        self.subtopic_pattern = subtopic_pattern\n",
    "\n",
    "    def split_text(self, text):\n",
    "        # First, split by chapters\n",
    "        texts = super().split_text(text)\n",
    "        documents = []\n",
    "        \n",
    "        # For each chapter, split by subtopic using the subtopic regex\n",
    "        chapter_number = 1\n",
    "        for chapter in texts:\n",
    "            subtopic_splits = self._split_by_subtopic(chapter, chapter_number)\n",
    "            documents.extend(subtopic_splits)\n",
    "            chapter_number += 1\n",
    "        \n",
    "        return documents\n",
    "\n",
    "    def _split_by_subtopic(self, text, chapter_number):\n",
    "        # Use the subtopic regex to split text\n",
    "        matches = list(self.subtopic_pattern.finditer(text))\n",
    "        if not matches:\n",
    "            # No subtopics found, return the full text as a single Document\n",
    "            return [Document(page_content=text.strip(), metadata={\"chapter\": chapter_number})]\n",
    "        \n",
    "        subtopics = []\n",
    "        start_idx = 0\n",
    "        subtopic_number = 1\n",
    "        \n",
    "        for match in matches:\n",
    "            end_idx = match.start()\n",
    "            if start_idx != end_idx:\n",
    "                subtopics.append(Document(\n",
    "                    page_content=text[start_idx:end_idx].strip(),\n",
    "                    metadata={\"chapter\": chapter_number, \"subtopic\": subtopic_number}\n",
    "                ))\n",
    "            start_idx = end_idx\n",
    "            subtopic_number += 1\n",
    "            \n",
    "        # Append the remaining part as a subtopic\n",
    "        subtopics.append(Document(\n",
    "            page_content=text[start_idx:].strip(),\n",
    "            metadata={\"chapter\": chapter_number, \"subtopic\": subtopic_number}\n",
    "        ))\n",
    "        \n",
    "        return subtopics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings and handle storage\n",
    "def embed_documents(split_docs, embedding_model):\n",
    "    EMBEDDINGS_FOLDER = \"embeddings\"\n",
    "    EMBEDDINGS_FILE = os.path.join(EMBEDDINGS_FOLDER, \"emb01.pkl\")\n",
    "\n",
    "    if not os.path.exists(EMBEDDINGS_FOLDER):\n",
    "        os.makedirs(EMBEDDINGS_FOLDER)\n",
    "\n",
    "    if os.path.exists(EMBEDDINGS_FILE):\n",
    "        print(f\"Loading existing embeddings from {EMBEDDINGS_FILE}...\")\n",
    "        with open(EMBEDDINGS_FILE, 'rb') as f:\n",
    "            embedded_docs = pickle.load(f)\n",
    "    else:\n",
    "        print(\"Creating new embeddings...\")\n",
    "        texts = [doc.page_content for doc in split_docs]\n",
    "        embedded_docs = embedding_model.embed_documents(texts)\n",
    "\n",
    "        with open(EMBEDDINGS_FILE, 'wb') as f:\n",
    "            pickle.dump(embedded_docs, f)\n",
    "\n",
    "    return embedded_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store embeddings in Chroma vector store\n",
    "def store_embeddings(split_docs, embedding_model):\n",
    "    vector_store = Chroma.from_documents(split_docs, embedding_model) \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RAG pipeline\n",
    "def build_rag_pipeline(vector_store):\n",
    "    retriever = vector_store.as_retriever()\n",
    "    return retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the LLM\n",
    "def initialize_llm():\n",
    "    llm = ChatGroq(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        temperature=0.1,\n",
    "    )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying the retriever and LLM\n",
    "def query_llm(llm, retriever, query):\n",
    "    # Retrieve relevant documents\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "\n",
    "    # Use the LLM to process the retrieved documents\n",
    "    if results:\n",
    "        # Combine results for the LLM prompt, and track their sources\n",
    "        context = \"\\n\".join([doc.page_content for doc in results])\n",
    "        prompt = f\"\"\"Use relevant information from 9th to 12th-grade textbooks to answer the student's query. If the context is helpful, incorporate it; otherwise, provide a general explanation. Avoid mentioning irrelevance and instead say, \"I cannot find relevant data from your book but I will explain the general concept.\" Encourage the student to ask follow-up questions related to the topics in the books.\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "        Student Query:\n",
    "        {query}\n",
    "        \"\"\"\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        # Capture the actual text chunks used\n",
    "        relevant_texts = [doc.page_content for doc in results]\n",
    "        \n",
    "        # Return both the response and relevant texts\n",
    "        return response, relevant_texts\n",
    "    else:\n",
    "        return \"No relevant documents found.\", []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='1.2.1 Definition\n",
      "A flowchart is a graphical presentation of the steps to solve\n",
      "Take shoes and socks\n",
      "Wear socks Wear shoes\n",
      "a problem. We use symbols for each step, and these symbols are connected with the help of arrows to show the flow of processing.\n",
      "Figure 1-6 shows a flowchart for the simple problem of wearing shoes with socks. It shows that not only the steps - | are important but also the order to complete a process. A Figure 1-6\n",
      "Sample flowchart\n",
      "Unit 1 — Problem Solving\n",
      "flowchart is used to visually communicate the steps in a process.' metadata={'chapter': 1, 'subtopic': 11}\n",
      "Creating new embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your document\n",
    "    # documents = load_documents('resources/9thComputerScience_cleaned.txt')\n",
    "    with open('resources/9thComputerScience_cleaned.txt', 'r') as file:\n",
    "        documents = file.read()\n",
    "    # Split the text into smaller chunks\n",
    "    text_splitter = CustomTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    split_docs = text_splitter.split_text(documents)\n",
    "    print(split_docs[10])\n",
    "    embedded_docs = embed_documents(split_docs, embedding_model)\n",
    "    vector_store = store_embeddings(split_docs, embedding_model)\n",
    "    retriever = build_rag_pipeline(vector_store)\n",
    "    \n",
    "    # Initialize the LLM\n",
    "    llm = initialize_llm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zubay\\AppData\\Local\\Temp\\ipykernel_23056\\3618850719.py:4: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Boolean proposition is a statement that can either be true or false. It's a sentence that has a clear meaning and can be classified as either true (T) or false (F). \n",
      "\n",
      "In the context of your textbook, a proposition is defined as a sentence that can either be true or false. For example:\n",
      "\n",
      "1. \"Someone from our school can join Pakistani Cricket Team\" is a proposition because it can be either true or false.\n",
      "2. \"I will get A+ grade in board exam\" is also a proposition because it can be either true or false.\n",
      "\n",
      "On the other hand, sentences like \"How are you?\" or \"Close the door\" are not propositions because they are questions or commands, and they don't have a clear true or false value.\n",
      "\n",
      "In Boolean algebra, propositions are often represented by letters, such as P or Q. For example:\n",
      "\n",
      "P = \"I play chess\"\n",
      "Q = \"I want to excel in mathematics\"\n",
      "\n",
      "When we say P, it means that we are referring to the proposition \"I play chess\", and when we say Q, it means that we are referring to the proposition \"I want to excel in mathematics\".\n",
      "\n",
      "Do you have any follow-up questions about Boolean propositions or would you like to know more about how they are used in Boolean algebra?\n",
      "==============================================\n",
      "\n",
      "Relevant text chunks used in the response:\n",
      "Chunk: ==============================\n",
      "2.5 Boolean Algebra\n",
      "Chunk: ==============================\n",
      "2.7\n",
      "Draw the truth table to verify A+ (B-C) = (A+ B): (A+ C0)\n",
      "e Identity Law If a variable is OR’ed with a False, the result is always equal to that variable. And if a variable is AND‘ed with a True, the result is always equal to that variable.\n",
      "a) A OR False = A, A variable OR’ed with False is alway\n",
      "Chunk: ==============================\n",
      "2.5.5 Laws of Boolean Algebra The laws of Boolean Algebra help us to simplify complex Boolean expressions. Some laws are discussed in the following.\n",
      "e Commutative Law Commutative Law states that the order of application of two separate propositions is not important. So,\n",
      "a) A.B=B8B.A (The order in wh\n",
      "Chunk: ==============================\n",
      "2.5.1 Boolean Proposition\n",
      "A proposition is a sentence that can either be true or false. For example, the following sentences are propositions.\n",
      "1. “Someone from our school can join Pakistani Cricket Team”\n",
      "2. “I will get A+ grade in board exam\"\n",
      "3. “I want to excel in mathematics”\n",
      "4. “This year Pakista\n"
     ]
    }
   ],
   "source": [
    "# # Example query \n",
    "query = \"explain boolean proposition\"\n",
    "response, relevant_texts = query_llm(llm, retriever, query)\n",
    "\n",
    "# # Output response and relevant text chunks\n",
    "print(response.content)\n",
    "print(\"==============================================\")\n",
    "print(\"\\nRelevant text chunks used in the response:\")\n",
    "for text in relevant_texts:\n",
    "    print(\"Chunk: ==============================\")\n",
    "    print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "2.5 Boolean Algebra\n",
      "=====================================\n",
      "2.7\n",
      "Draw the truth table to verify A+ (B-C) = (A+ B): (A+ C0)\n",
      "e Identity Law If a variable is OR’ed with a False, the result is always equal to that variable. And if a variable is AND‘ed with a True, the result is always equal to that variable.\n",
      "a) A OR False = A, A variable OR’ed with False is always equal to that variable\n",
      "b) A AND True =A, A variable AND’ed with True is always equal to that variable\n",
      "=====================================\n",
      "2.5.5 Laws of Boolean Algebra The laws of Boolean Algebra help us to simplify complex Boolean expressions. Some laws are discussed in the following.\n",
      "e Commutative Law Commutative Law states that the order of application of two separate propositions is not important. So,\n",
      "a) A.B=B8B.A (The order in which two variables are AND’ed makes no difference.)\n",
      "b) A+B=B+A _ (The order in which two variables are OR’ed makes no difference.)\n",
      "We can use truth tables (Table 2-13a, Table 2-13b) to verify this law for AND and OR operations respectively.\n",
      "Table 2-13a Table 2-13b\n",
      "We can observe from Table 2-13a that both the columns A-BandB-A contain same values in each row. Thus it verifies the commutative law for AND operation. Similarly we can verify for OR operation from Table\n",
      "=====================================\n",
      "2.5.1 Boolean Proposition\n",
      "A proposition is a sentence that can either be true or false. For example, the following sentences are propositions.\n",
      "1. “Someone from our school can join Pakistani Cricket Team”\n",
      "2. “I will get A+ grade in board exam\"\n",
      "3. “I want to excel in mathematics”\n",
      "4. “This year Pakistan Super League (PSL) final match will be played in Lahore”\n",
      "5. “I play chess”.\n",
      "But the following sentences are not propositions 1. How are you? 2. Close the door. 3. Is it hot outside?\n",
      "We can also assign some letter to a proposition, as shown in the following.\n",
      "1- P = “I play chess”. 2- Q = “IT want to excel in mathematics” Now, when we say P, it means that we are referring to proposition “I play\n",
      "chess”, and when we say Q, it means that we are referring to proposition “I want to excel in mathematics”.\n",
      "Do you know?\n",
      "True and False are called Boolean values. The idea was given by George Boole (2 November 1815 —8 December 1864) in his book “The Laws of Thought”.\n"
     ]
    }
   ],
   "source": [
    "for text in relevant_texts:\n",
    "    print(\"=====================================\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example query \n",
    "# query = \"who gave the idea of boolean values and on what date\"\n",
    "# response, relevant_texts = query_llm(llm, retriever, query)\n",
    "\n",
    "# # Output response and relevant text chunks\n",
    "# print(response.content)\n",
    "# print(\"==============================================\")\n",
    "# print(\"\\nRelevant text chunks used in the response:\")\n",
    "# for text in relevant_texts:\n",
    "#     print(\"Chunk: ==============================\")\n",
    "#     print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example query \n",
    "# query = \"how ip4 and ip6 works\"\n",
    "# response, relevant_texts = query_llm(llm, retriever, query)\n",
    "\n",
    "# # Output response and relevant text chunks\n",
    "# print(response.content)\n",
    "# print(\"==============================================\")\n",
    "# print(\"\\nRelevant text chunks used in the response:\")\n",
    "# for text in relevant_texts:\n",
    "#     print(\"Chunk: ==============================\")\n",
    "#     print(text[:300])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
